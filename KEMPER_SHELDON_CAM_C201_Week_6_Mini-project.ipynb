{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sheldonkemper/portfolio/blob/main/KEMPER_SHELDON_CAM_C201_Week_6_Mini-project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mini-project 6.3 Applying supervised learning to predict student dropout rate\n",
        "\n",
        "**Welcome to your Mini-project: Applying supervised learning to predict student dropout rate!**\n",
        "\n",
        "In this project, we will examine student data and use supervised learning techniques to predict whether a student will drop out. In the education sector, retaining students is vital for the institution's financial stability and for students’ academic success and personal development. A high dropout rate can lead to significant revenue loss, diminished institutional reputation, and lower overall student satisfaction.\n",
        "\n",
        "Please set aside approximately **12 hours** to complete the mini-project.\n",
        "\n",
        "<br></br>\n",
        "\n",
        "## **Business context**\n",
        "Study Group specialises in providing educational services and resources to students and professionals across various fields. The company's primary focus is on enhancing learning experiences through a range of services, including online courses, tutoring, and educational consulting. By leveraging cutting-edge technology and a team of experienced educators, Study Group aims to bridge the gap between traditional learning methods and the evolving needs of today's learners.\n",
        "\n",
        "Study Group serves its university partners by establishing strategic partnerships to enhance the universities’ global reach and diversity. It supports the universities in their efforts to attract international students, thereby enriching the cultural and academic landscape of their campuses. It works closely with university faculty and staff to ensure that the universities are prepared and equipped to welcome and support a growing international student body. Its partnership with universities also offers international students a seamless transition into their chosen academic environment. Study Group runs several International Study Centres across the UK and Dublin in partnership with universities with the aim of preparing a pipeline of talented international students from diverse backgrounds for degree study. These centres help international students adapt to the academic, cultural, and social aspects of studying abroad. This is achieved by improving conversational and subject-specific language skills and academic readiness before students progress to a full degree programme at university.\n",
        "\n",
        "Through its comprehensive suite of services, it supports learners and universities at every stage of their educational journey, from high school to postgraduate studies. Its approach is tailored to meet the unique needs of each learner, offering personalised learning paths and flexible scheduling options to accommodate various learning styles and commitments.\n",
        "\n",
        "Study Group's services are designed to be accessible and affordable, making quality education a reality for many individuals. By focusing on the integration of technology and personalised learning, the company aims to empower learners to achieve their full potential and succeed in their academic and professional pursuits. Study Group is at the forefront of transforming how people learn and grow through its dedication to innovation and excellence.\n",
        "Study Group has provided you a course-level data set.\n",
        "\n",
        "\n",
        "<br></br>\n",
        "\n",
        "## **Objective**\n",
        "By the end of this mini-project, you will have developed the skills and knowledge to apply advanced machine learning techniques to create a predictive model for student dropout. This project will involve comprehensive data exploration, preprocessing, and feature engineering to ensure high-quality input for the models. You will employ and compare multiple predictive algorithms - XGBoost and neural network-based model, to determine the most effective model for predicting student dropout.\n",
        "\n",
        "In the Notebook, you will:\n",
        "- explore the data set\n",
        "- preprocess the data and conduct feature engineering\n",
        "- predict dropout using XGBoost, and neural network-based model\n",
        "- Identify the most important predictors of dropout.\n",
        "\n",
        "\n",
        "You will also write a report summarising the results of your findings and recommendations.\n",
        "\n",
        "<br></br>\n",
        "\n",
        "## **Assessment criteria**\n",
        "By completing this project, you will be able to provide evidence that you can:\n",
        "- develop accurate predictions across diverse organisational scenarios by building and testing advanced machine learning models\n",
        "- inform data-driven decision-making with advanced machine learning algorithms and models\n",
        "- propose and present effective solutions to organisational problems using data preprocessing, model selection, and insightful analysis techniques.\n",
        "\n",
        "<br></br>\n",
        "\n",
        "## **Project guidance**\n",
        "\n",
        "Data preparation\n",
        "1. Import the required libraries and data set with the provided URL.\n",
        "  - Data set drive: https://drive.google.com/drive/folders/130AVMFxTOtRiC7GOl7QmSo0I7B0iChv5\n",
        "2. Read the course-level csv file and make it available as a dataframe.\n",
        "\n",
        "3. From the dataframe, remove the following columns:\n",
        "\n",
        "columns= ['BookingId','BookingType', 'LeadSource', 'DiscountType',\n",
        "                                                    'Nationality', 'HomeCountry',\n",
        "                                                    'HomeState',\n",
        "                                                    'HomeCity',\n",
        "                                                    'PresentCount',\n",
        "                                                    'LateCount', 'AuthorisedAbsenceCount','ArrivedDate','NonCompletionReason',\n",
        "                                                    'TerminationDate',\n",
        "                                                    'CourseFirstIntakeDate', 'CourseStartDate','CourseEndDate',\n",
        "                                                    'AcademicYear', 'CourseName',\n",
        "                                                    'LearnerCode', 'ProgressionDegree',\n",
        "                                                    'EligibleToProgress',\n",
        "                                                    'AssessedModules',\n",
        "                                                    'PassedModules',\n",
        "                                                    'FailedModules',\n",
        "                                                    'AttendancePercentage',\n",
        "                                                    'ContactHours']\n",
        "\n",
        "From here on, you will perform the rest of the actvities mentioned in the rubric with the smaller set of features obtained after performing the above step.\n",
        "\n",
        "General Instructions that apply throughout this project activity:\n",
        "  - Use the standard scaler to scale your numeric input features.\n",
        "  - Split the data into train and test sets. Apply 80-20 split.\n",
        "  - Print accuracy, confusion matrix, precision, recall and AUC on the test set\n",
        "    for all your models.\n",
        "  - Compare the performance (on the test set) obtained from the non-optimised\n",
        "    model with the best performing model. Record your observations. What differences do you see and which metrics are improved or not improved?\n",
        "\n",
        "## Please refer to the Rubric for specific steps to be performed as part of the project activity. Every step mentioned in the rubric will be assessed separately.\n",
        "\n",
        "Report\n",
        "1. Document your approach and major inferences from the data analysis and describe which method provided the best results and why.\n",
        "  - Please ensure you include a discussion around which of the features will predict student droput.\n",
        "2. When you’ve completed the project:\n",
        "  - Download your completed Notebook as an IPYNB (Jupyter Notebook) or PY (Python) file. Save the file as follows: **LastName_FirstName_CAM_C201_Week_6_Mini-project**.\n",
        "  - Prepare a detailed report (between 800-1,000 words) that includes:\n",
        "    - an overview of your approach\n",
        "    - a description of your analysis\n",
        "    - an explanation of the insights you identified\n",
        "    - a summary of which method gave the best results\n",
        "    - an explanation of visualisations you created.\n",
        "  - Save the document as a PDF named according to the following convention: **LastName_FirstName_CAM_C201_Week_6_Mini-project.pdf**.\n",
        "  \n",
        "\n",
        "\n",
        "<br></br>\n",
        "> **Declaration**\n",
        ">\n",
        "> By submitting your project, you indicate that the work is your own and has been created with academic integrity. Refer to the Cambridge plagiarism regulations."
      ],
      "metadata": {
        "id": "9j5Bse6izKKh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Initial Data Exploration and Assessment\n"
      ],
      "metadata": {
        "id": "PrWEm2Byqmg5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Data Loading and Initial Exploration"
      ],
      "metadata": {
        "id": "Ic_NPeDSr-oa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the dataset."
      ],
      "metadata": {
        "id": "mAbtR5maXT4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display basic statistics (df.describe(), df.info())."
      ],
      "metadata": {
        "id": "9F9NIdMLsQUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values"
      ],
      "metadata": {
        "id": "LNleKkkV2F1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Handling Missing Values"
      ],
      "metadata": {
        "id": "PIsY0uLSsB_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove any rows with missing values"
      ],
      "metadata": {
        "id": "IfeHHTKHsJBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Filtering Columns"
      ],
      "metadata": {
        "id": "0ycCAmZ1sfh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out the requested columns as per the project starter notebook."
      ],
      "metadata": {
        "id": "fzgs7rAssiNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Feature Engineering: Convert Date of Birth to Age"
      ],
      "metadata": {
        "id": "eUn3gjG2srnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'DateofBirth' into a new 'Age' column."
      ],
      "metadata": {
        "id": "6LaR9GZfsvFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 Feature Engineering: Scaling Numerical Columns"
      ],
      "metadata": {
        "id": "os-N5NOps2u1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply StandardScaler to scale the numerical input features."
      ],
      "metadata": {
        "id": "RY_ZU2sgs8PN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.6 Feature Engineering: Binary Encoding of Target Variable"
      ],
      "metadata": {
        "id": "GOW5tnMqtBE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the target variable from string to binary encoding."
      ],
      "metadata": {
        "id": "K1TC-EIJtEb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.7 Feature Engineering: One-Hot Encoding of Categorical Features"
      ],
      "metadata": {
        "id": "eZ5OuiKgtLpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply one-hot encoding to the categorical columns"
      ],
      "metadata": {
        "id": "-S5f0m5ptRBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.8 Target Variable Histogram"
      ],
      "metadata": {
        "id": "7ngbPFnDtWgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a histogram of the target variable to check if the data is imbalanced."
      ],
      "metadata": {
        "id": "z1Bje3KNtYip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.9 Boxplots of Input Features Grouped by Target"
      ],
      "metadata": {
        "id": "Qgakv27wtfTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create boxplots of numerical input features grouped by the target variable."
      ],
      "metadata": {
        "id": "fedx2qCxtiaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.10 Train-Test Split"
      ],
      "metadata": {
        "id": "OgKoDOa7tod7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and test sets (80-20 split)."
      ],
      "metadata": {
        "id": "xKkFuKx2ttwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. XGBoost Model"
      ],
      "metadata": {
        "id": "YygzFxTzqwNQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Model Instantiation"
      ],
      "metadata": {
        "id": "oZri0y3zt_uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the XGBClassifier correctly for the dataset."
      ],
      "metadata": {
        "id": "W4Bg5YVdqyd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Fitting the Model"
      ],
      "metadata": {
        "id": "h8YGqAxhuIQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model on the training data."
      ],
      "metadata": {
        "id": "1qJ4PJhKuKYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Model Evaluation on Test Set"
      ],
      "metadata": {
        "id": "sMOAXfCtuSRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Print performance metrics for the test set:\n",
        "Accuracy\n",
        "Confusion matrix\n",
        "Precision\n",
        "Recall\n",
        "AUC\n",
        "'''"
      ],
      "metadata": {
        "id": "3GH-GjS4uUhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "2ea-kqLWuxgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Perform hyperparameter tuning for\n",
        "learning rate, max depth, and number of estimators\n",
        "using GridSearchCV or RandomizedSearchCV.\n",
        "'''"
      ],
      "metadata": {
        "id": "jNI-Pa9Ju0Gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Print the metrics:\n",
        "accuracy, confusion matrix, precision, recall, AUC\n",
        "with and without hyperparameter tuning.\n",
        "'''"
      ],
      "metadata": {
        "id": "dJdrsyxQvKfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Compare the results and\n",
        "comment on any differences in performance\n",
        "'''"
      ],
      "metadata": {
        "id": "t_ReVfoCvYZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 Reintroducing Features"
      ],
      "metadata": {
        "id": "zM4ghJeevhel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add back 'ContactHours' and 'AttendancePercentage' to the dataset."
      ],
      "metadata": {
        "id": "phDR3Z_uvnC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrain the model and evaluate its performance on the test set."
      ],
      "metadata": {
        "id": "UPVX8kLvvso-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare the new metrics and explain the impact of reintroducing these features."
      ],
      "metadata": {
        "id": "ZseNopxivwCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.6 Feature Importance Plot"
      ],
      "metadata": {
        "id": "QSMCe-mrv0ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot feature importance, keeping the two additional features ('ContactHours' and 'AttendancePercentage')."
      ],
      "metadata": {
        "id": "FqIng7Y1v2qS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comment on the most important predictors based on the plot."
      ],
      "metadata": {
        "id": "QCyMUwYcwFYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO"
      ],
      "metadata": {
        "id": "xX65OraywVSM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Neural Network Model"
      ],
      "metadata": {
        "id": "kBvTeQgEq3TK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Model Definition and Instantiation"
      ],
      "metadata": {
        "id": "8NeFxcMWwY5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define and instantiate the neural network model using Keras or TensorFlow."
      ],
      "metadata": {
        "id": "DoL9R1fKwbj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Model Fitting"
      ],
      "metadata": {
        "id": "SR_jtCBfwhQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model on the training data."
      ],
      "metadata": {
        "id": "2Ys7NxGwwl4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Plotting Loss Curves"
      ],
      "metadata": {
        "id": "bfDaQlotwqNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loss curves for each epoch, showing both training and validation loss."
      ],
      "metadata": {
        "id": "rQwPK34ewsfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 Model Evaluation on Test Set"
      ],
      "metadata": {
        "id": "hB6_UfYOw0Qa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Print performance metrics for the test set:\n",
        "Accuracy\n",
        "Confusion matrix\n",
        "Precision\n",
        "Recall\n",
        "AUC\n",
        "'''"
      ],
      "metadata": {
        "id": "YVjkW0Uzw4_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.5 Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "BHXZBKLBxAD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Perform hyperparameter tuning, experimenting with:\n",
        "Number of neurons\n",
        "Optimisers (e.g., Adam, RMSProp)\n",
        "Activation functions (e.g., ReLU, sigmoid)\n",
        "'''"
      ],
      "metadata": {
        "id": "Q8VjI2oZxCAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Print and compare the metrics\n",
        "with and without hyperparameter tuning\n",
        "'''"
      ],
      "metadata": {
        "id": "Hto1hf9exPuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discuss the differences and improvements, if any."
      ],
      "metadata": {
        "id": "iw6_zU_UxaUQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO"
      ],
      "metadata": {
        "id": "vB8VXS5sxeJ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.6 Reintroducing Features"
      ],
      "metadata": {
        "id": "VnKwC3HPxj7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add back 'ContactHours' and 'AttendancePercentage' to the dataset."
      ],
      "metadata": {
        "id": "7qWC_7RDxpR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrain the neural network and evaluate performance on the test set."
      ],
      "metadata": {
        "id": "G22SgNbUxtZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Compare the metrics and\n",
        "explain any performance changes caused by the additional features.\n",
        "'''"
      ],
      "metadata": {
        "id": "xJR7McK-x0FM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}