{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sheldonkemper/portfolio/blob/main/Copy_of_CAM_DS_301_Sentiment_analysis_and_text_classification_Activity_2_2_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Activity 2.2.6 Sentiment analysis and text classification\n",
        "\n",
        "In this activity, you will build a sentiment analysis model using Python and a data set of customer reviews. You will preprocess the data and fine-tune, evaluate, and test the model.\n",
        "\n",
        "\n",
        "## Objective\n",
        "In this activity, you will download a data set from Hugging Face and conduct text classification on it. Your objective is to analyse how different parameter choices affect the performance of a sentiment classifier.\n",
        "\n",
        "You will complete this in your Notebook, where you will:\n",
        "\n",
        "- create and train sentiment classifier RNN models\n",
        "- evaluate model performance.\n",
        "\n",
        "\n",
        "\n",
        "## Assessment criteria\n",
        "\n",
        "By completing this activity, you will be able to provide evidence that you can:\n",
        "*   apply various text preprocessing techniques and representation methods to preprocess and analyse textual data.\n",
        "*   comprehend and implement different types of recurrent neural networks (RNNs) and understand their applications in NLP.\n",
        "*   build and fine-tune advanced NLP models for specific natural language processing tasks.\n",
        "\n",
        "\n",
        "## Activity guidance\n",
        "\n",
        "1. Install the necessary packages that will be useful in this activity\n",
        "2. Load the dataset sst5 from hugging face (https://huggingface.co/datasets/SetFit/sst5)\n",
        "\n",
        "3. Create dataframes of the train and train split\n",
        "4. Split the train dataframe into train and validation in the ratio of 8:2\n",
        "5. Preprocess the dataset, set the maximum size to 200, vocabulary size to 30000\n",
        "6. During tokenisation, mark out of vocabulary words as \"[OOV]\"\n",
        "7. Pad your sequences with special tokens\n",
        "8. Train a sentiment classifier on the dataset and compare different models for text classification\n",
        "9.Train for 5 epochs\n",
        "- Train with a vanilla RNN\n",
        "- Train with an LSTM\n",
        "- Is there any difference between a GRU and an LSTM?\n",
        "- Train with a bidirectional LSTM\n",
        "10. Comment on the performance of all the models\n"
      ],
      "metadata": {
        "id": "bJt5DBRG6FsS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Start your activity here. Select the pen from the toolbar to add your entry."
      ],
      "metadata": {
        "id": "wUMKlbI5Cc3T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJ4plMp0wAra"
      },
      "outputs": [],
      "source": [
        "#In this activity, you will be required to download a dataset from huggingface and perfom the text classification on the the dataset\n",
        "#You will be required to study the impact of different different parameter choices on the classification perfomance of sentiment classifier\n",
        "\n",
        "\n",
        "#1. Install the necessary packages that will be useful in this  activity\n",
        "#2. Load the dataset sst5 from hugginface (https://huggingface.co/datasets/SetFit/sst5)\n",
        "#3.Create dataframes of the train and train split\n",
        "#4 Split the train dataframe into train and validation in the ratio of 8:2\n",
        "#5 Preprocess the dataset,  set the maximum size to 200, vocabulary size to 30000\n",
        "#6. During tokenization, mark out of vocabulary words as \"<OOV>\"\n",
        "#7 Pad your sequences with special tokens\n",
        "#8. Train a sentiment classifier on the dataset and compare different models for text classification\n",
        "# Train for 5 epochs\n",
        "#    - Train with a vanilla RNN\n",
        "#    - Train with an LSTM\n",
        "#    - Is there any difference between a GRU and an LSTM?\n",
        "#    - Train with a bidirectional LSTM\n",
        "# Comment on the perfomance of all the models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 1: Install Necessary Packages**\n",
        "\n"
      ],
      "metadata": {
        "id": "7fUAZyKeOJe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrqBL1cGN57x",
        "outputId": "48f621b3-9bb2-4894-a3e0-b46a23ae1f73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.3)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 2: Load the Dataset from Hugging Face**"
      ],
      "metadata": {
        "id": "3jLCWeXEOObh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the sst5 dataset\n",
        "dataset = load_dataset(\"SetFit/sst5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_U8uTfzAOA1l",
        "outputId": "4c02767a-93e0-452b-f3a1-36ed2d75e92a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset['train'][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbBknuducn_a",
        "outputId": "2db3548f-a5c0-4307-c97d-5a4ff03ce6f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': 'a stirring , funny and finally transporting re-imagining of beauty and the beast and 1930s horror films', 'label': 4, 'label_text': 'very positive'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 3: Create DataFrames for Train and Test Splits**"
      ],
      "metadata": {
        "id": "__c7kydEOWfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert train and test splits into DataFrames\n",
        "train_df = pd.DataFrame(dataset['train'])\n",
        "test_df = pd.DataFrame(dataset['test'])"
      ],
      "metadata": {
        "id": "G2yWBAyhOUVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of each DataFrame to confirm the conversion\n",
        "print(train_df.head())\n",
        "print(test_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNhnqT0Cd0wn",
        "outputId": "91d95dcc-ff0c-4577-cf5f-acd25ce5c8a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  label     label_text\n",
            "0  a stirring , funny and finally transporting re...      4  very positive\n",
            "1  apparently reassembled from the cutting-room f...      1       negative\n",
            "2  they presume their audience wo n't sit still f...      1       negative\n",
            "3  the entire movie is filled with deja vu moments .      2        neutral\n",
            "4  this is a visually stunning rumination on love...      3       positive\n",
            "                                                text  label     label_text\n",
            "0     no movement , no yuks , not much of anything .      1       negative\n",
            "1  a gob of drivel so sickly sweet , even the eag...      0  very negative\n",
            "2  ` how many more voyages can this limping but d...      2        neutral\n",
            "3  so relentlessly wholesome it made me want to s...      2        neutral\n",
            "4  gangs of new york is an unapologetic mess , wh...      0  very negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 4: Split Train Data into Train and Validation (80:20)**"
      ],
      "metadata": {
        "id": "p__9P-bDOboV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "CLOzVU43PAXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training set size: {len(train_df)}\")\n",
        "print(f\"Validation set size: {len(val_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHVcK7_aeCIJ",
        "outputId": "49163c10-b24c-4a64-9d6b-6268462e805e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 6835\n",
            "Validation set size: 1709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check unique label values in each split\n",
        "print(\"Unique labels in training set:\", train_df['label'].unique())\n",
        "print(\"Unique labels in validation set:\", val_df['label'].unique())\n",
        "print(\"Unique labels in test set:\", test_df['label'].unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMhphkZslZxY",
        "outputId": "e2c52b88-be8e-44f9-972d-55d318cc574a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique labels in training set: [3 2 1 4 0]\n",
            "Unique labels in validation set: [3 4 1 2 0]\n",
            "Unique labels in test set: [1 0 2 4 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 5: Preprocess the Dataset**"
      ],
      "metadata": {
        "id": "9Cib_HTXOdg9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the maximum sequence length to 200 and the vocabulary size to 30,000.\n",
        "\n",
        "During tokenization, mark out-of-vocabulary (OOV) words as \"[OOV]\".\n",
        "\n",
        "1. Tokenize: Use a tokenizer, such as one from the Hugging Face library, with a maximum length and OOV handling.\n",
        "1. Padding: Add padding tokens to ensure each sequence is exactly 200 tokens long."
      ],
      "metadata": {
        "id": "GacjFl7wQwds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Initialize the tokenizer with specific settings\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "max_len = 200  # Maximum sequence length\n",
        "vocab_size = 30000  # Vocabulary size\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3ioQt6jZAAC",
        "outputId": "fc435dff-f1ab-4bc5-f1ce-e124ddeefa03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the tokenizer with an out-of-vocabulary word\n",
        "sample_text = \"This is a sample sentence with an oovwordtest that should be replaced.\"\n",
        "\n",
        "# Tokenize the sample text\n",
        "tokens = tokenizer(sample_text, max_length=max_len, padding=\"max_length\", truncation=True)\n",
        "print(\"Token IDs:\", tokens['input_ids'])\n",
        "print(\"Decoded Tokens:\", tokenizer.convert_ids_to_tokens(tokens['input_ids']))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xWlFKroeSUe",
        "outputId": "d936cea0-a1a1-4611-9724-0b72dc79c08c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs: [101, 2023, 2003, 1037, 7099, 6251, 2007, 2019, 1051, 4492, 18351, 22199, 2008, 2323, 2022, 2999, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Decoded Tokens: ['[CLS]', 'this', 'is', 'a', 'sample', 'sentence', 'with', 'an', 'o', '##ov', '##word', '##test', 'that', 'should', 'be', 'replaced', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf # Import the TensorFlow library\n",
        "\n",
        "# Tokenize and preprocess the dataset\n",
        "def tokenize_and_encode(df):\n",
        "    return tokenizer(\n",
        "        df['text'].tolist(),\n",
        "        max_length=max_len,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"tf\"\n",
        "    )\n",
        "\n",
        "# Tokenize and prepare inputs for each dataset\n",
        "train_encodings = tokenize_and_encode(train_df)\n",
        "val_encodings = tokenize_and_encode(val_df)\n",
        "test_encodings = tokenize_and_encode(test_df)\n",
        "\n",
        "# Convert labels to tensors\n",
        "train_labels = tf.convert_to_tensor(train_df['label'].values)\n",
        "val_labels = tf.convert_to_tensor(val_df['label'].values)\n",
        "test_labels = tf.convert_to_tensor(test_df['label'].values)\n",
        "\n",
        "# Create TensorFlow Datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(({\n",
        "    'input_ids': train_encodings['input_ids'],\n",
        "    'attention_mask': train_encodings['attention_mask']\n",
        "}, train_labels)).batch(32)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices(({\n",
        "    'input_ids': val_encodings['input_ids'],\n",
        "    'attention_mask': val_encodings['attention_mask']\n",
        "}, val_labels)).batch(32)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(({\n",
        "    'input_ids': test_encodings['input_ids'],\n",
        "    'attention_mask': test_encodings['attention_mask']\n",
        "}, test_labels)).batch(32)\n"
      ],
      "metadata": {
        "id": "-7EYGpnsO_8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print tokenized outputs for train_encodings\n",
        "print(\"Sample input IDs:\", train_encodings['input_ids'][0])\n",
        "print(\"Sample attention mask:\", train_encodings['attention_mask'][0])\n",
        "print(\"Length of input IDs:\", len(train_encodings['input_ids'][0]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdTFFnFVgBWd",
        "outputId": "126b7002-e9da-45b3-b94f-b775c48496b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample input IDs: tf.Tensor(\n",
            "[ 101 1010 1036 1036 2027 1005 2128 2041 2045  999 1005 1005  102    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0], shape=(200,), dtype=int32)\n",
            "Sample attention mask: tf.Tensor(\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(200,), dtype=int32)\n",
            "Length of input IDs: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a batch from the train dataset\n",
        "for batch in train_dataset.take(1):\n",
        "    inputs, labels = batch\n",
        "    print(\"Input IDs shape:\", inputs['input_ids'].shape)\n",
        "    print(\"Attention mask shape:\", inputs['attention_mask'].shape)\n",
        "    print(\"Labels shape:\", labels.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejLHfGIqgIdQ",
        "outputId": "661efdf6-023c-4a49-b0ff-d9b9e0d0b8d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input IDs shape: (32, 200)\n",
            "Attention mask shape: (32, 200)\n",
            "Labels shape: (32,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 6: Train a Sentiment Classifier and Compare Different Models**\n"
      ],
      "metadata": {
        "id": "KVi5rK_WOs5G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train for 5 Epochs\n",
        "\n",
        "For each model, train on the preprocessed training data for 5 epochs.\n",
        "\n",
        "Below are the steps for setting up each model type:\n",
        "\n",
        "1. Vanilla RNN\n",
        "1. LSTM\n",
        "1. GRU (Compare its performance with LSTM)\n",
        "1. Bidirectional LSTM\n"
      ],
      "metadata": {
        "id": "I97wtjdJQT1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, GRU, Bidirectional, Dense\n",
        "\n",
        "# Model and dataset parameters\n",
        "vocab_size = 30000  # Defined earlier\n",
        "embedding_dim = 300  # Embedding dimension\n",
        "max_len = 200  # Maximum sequence length"
      ],
      "metadata": {
        "id": "PYxhlYXaO-vA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, GRU, Bidirectional, Dense, Dropout\n",
        "\n",
        "def create_model(rnn_type='VanillaRNN', dropout_rate=0.3):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim))\n",
        "    model.add(Dropout(dropout_rate))  # Add dropout after embedding layer\n",
        "\n",
        "    # Add the RNN layer without return_sequences to get a single output\n",
        "    if rnn_type == 'VanillaRNN':\n",
        "        model.add(SimpleRNN(64))  # Remove `return_sequences=True`\n",
        "    elif rnn_type == 'LSTM':\n",
        "        model.add(LSTM(64))  # Remove `return_sequences=True`\n",
        "    elif rnn_type == 'GRU':\n",
        "        model.add(GRU(64))  # Remove `return_sequences=True`\n",
        "    elif rnn_type == 'BidirectionalLSTM':\n",
        "        model.add(Bidirectional(LSTM(64)))  # Remove `return_sequences=True`\n",
        "\n",
        "    model.add(Dropout(dropout_rate))  # Dropout after RNN layer\n",
        "    model.add(Dense(64, activation='relu'))  # Dense layer for extra learning capacity\n",
        "    model.add(Dropout(dropout_rate))  # Dropout for Dense layer\n",
        "\n",
        "    # Output layer for multi-class classification (5 classes)\n",
        "    model.add(Dense(5, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "OYMQ9xK-wy2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the unique label values\n",
        "print(\"Unique labels in training set:\", train_labels.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rex5gEkjr14O",
        "outputId": "987c23ad-9a04-4226-b2b8-83a7997e0e46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique labels in training set: [3 2 3 ... 0 3 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Convert train_labels to a NumPy array for compute_class_weight\n",
        "train_labels_np = train_labels.numpy() if isinstance(train_labels, tf.Tensor) else train_labels\n",
        "\n",
        "# Define class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels_np), y=train_labels_np)\n",
        "class_weights = {i: weight for i, weight in enumerate(class_weights)}\n",
        "\n",
        "print(\"Class Weights:\", class_weights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOYSD7KJrygF",
        "outputId": "cf0ac1ba-168d-4edf-bbc7-5f351f5a9de3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights: {0: 1.5516458569807037, 1: 0.7784738041002278, 2: 1.0356060606060606, 3: 0.7401191120736329, 4: 1.3258971871968963}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 7: Training and Evaluation**"
      ],
      "metadata": {
        "id": "DLBnSIk0OwuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create TensorFlow Datasets with only input_ids and labels\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_encodings['input_ids'], train_labels)).batch(32)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_encodings['input_ids'], val_labels)).batch(32)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_encodings['input_ids'], test_labels)).batch(32)\n"
      ],
      "metadata": {
        "id": "GFDTeyA0hFne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define dictionary to store validation accuracies for each model\n",
        "model_performance = {}\n",
        "\n",
        "# Train and evaluate each model, storing validation accuracy\n",
        "for model_type in ['VanillaRNN', 'LSTM', 'GRU', 'BidirectionalLSTM']:\n",
        "    print(f\"\\nTraining {model_type} model...\")\n",
        "    model = create_model(rnn_type=model_type, dropout_rate=0.3)\n",
        "    model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=val_dataset,\n",
        "        epochs=5,\n",
        "        class_weight=class_weights  # Applying the calculated class weights here\n",
        "    )\n",
        "    val_loss, val_accuracy = model.evaluate(val_dataset)\n",
        "    model_performance[model_type] = val_accuracy  # Store validation accuracy\n",
        "    print(f\"{model_type} Validation Accuracy: {val_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eFy-sJ8O9YE",
        "outputId": "ff496a38-470d-4f0c-eb1e-18da4b2f23a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training VanillaRNN model...\n",
            "Epoch 1/5\n",
            "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 369ms/step - accuracy: 0.1784 - loss: 1.6341 - val_accuracy: 0.1779 - val_loss: 1.6063\n",
            "Epoch 2/5\n",
            "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 306ms/step - accuracy: 0.1927 - loss: 1.6222 - val_accuracy: 0.2779 - val_loss: 1.6057\n",
            "Epoch 3/5\n",
            "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 273ms/step - accuracy: 0.1914 - loss: 1.6151 - val_accuracy: 0.1779 - val_loss: 1.6064\n",
            "Epoch 4/5\n",
            "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 307ms/step - accuracy: 0.2060 - loss: 1.6166 - val_accuracy: 0.2779 - val_loss: 1.6049\n",
            "Epoch 5/5\n",
            "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 273ms/step - accuracy: 0.2138 - loss: 1.6148 - val_accuracy: 0.1779 - val_loss: 1.6077\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.1838 - loss: 1.6080\n",
            "VanillaRNN Validation Accuracy: 0.1779\n",
            "\n",
            "Training LSTM model...\n",
            "Epoch 1/5\n",
            "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 505ms/step - accuracy: 0.1767 - loss: 1.6179 - val_accuracy: 0.1779 - val_loss: 1.6053\n",
            "Epoch 2/5\n",
            "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 510ms/step - accuracy: 0.2003 - loss: 1.6159 - val_accuracy: 0.1779 - val_loss: 1.6033\n",
            "Epoch 3/5\n",
            "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 531ms/step - accuracy: 0.2165 - loss: 1.6161 - val_accuracy: 0.2779 - val_loss: 1.6046\n",
            "Epoch 4/5\n",
            "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 497ms/step - accuracy: 0.1981 - loss: 1.6158 - val_accuracy: 0.2779 - val_loss: 1.6084\n",
            "Epoch 5/5\n",
            "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 587ms/step - accuracy: 0.2089 - loss: 1.6145 - val_accuracy: 0.2703 - val_loss: 1.6087\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.2627 - loss: 1.6087\n",
            "LSTM Validation Accuracy: 0.2703\n",
            "\n",
            "Training GRU model...\n",
            "Epoch 1/5\n",
            "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 527ms/step - accuracy: 0.1898 - loss: 1.6185 - val_accuracy: 0.1779 - val_loss: 1.6030\n",
            "Epoch 2/5\n",
            "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 537ms/step - accuracy: 0.2075 - loss: 1.6168 - val_accuracy: 0.1779 - val_loss: 1.6034\n",
            "Epoch 3/5\n",
            "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 501ms/step - accuracy: 0.1793 - loss: 1.6166 - val_accuracy: 0.2779 - val_loss: 1.6076\n",
            "Epoch 4/5\n",
            "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 544ms/step - accuracy: 0.1893 - loss: 1.6157 - val_accuracy: 0.1779 - val_loss: 1.6097\n",
            "Epoch 5/5\n",
            "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 524ms/step - accuracy: 0.2142 - loss: 1.6149 - val_accuracy: 0.1779 - val_loss: 1.6038\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.1838 - loss: 1.6044\n",
            "GRU Validation Accuracy: 0.1779\n",
            "\n",
            "Training BidirectionalLSTM model...\n",
            "Epoch 1/5\n",
            "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 823ms/step - accuracy: 0.2106 - loss: 1.6044 - val_accuracy: 0.2575 - val_loss: 1.4615\n",
            "Epoch 2/5\n",
            "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 803ms/step - accuracy: 0.3694 - loss: 1.3123 - val_accuracy: 0.3675 - val_loss: 1.4289\n",
            "Epoch 3/5\n",
            "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 857ms/step - accuracy: 0.5401 - loss: 1.0016 - val_accuracy: 0.3604 - val_loss: 1.5780\n",
            "Epoch 4/5\n",
            "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 853ms/step - accuracy: 0.6767 - loss: 0.7588 - val_accuracy: 0.3926 - val_loss: 1.9698\n",
            "Epoch 5/5\n",
            "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 843ms/step - accuracy: 0.7652 - loss: 0.5853 - val_accuracy: 0.3400 - val_loss: 2.1042\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 248ms/step - accuracy: 0.3297 - loss: 2.1250\n",
            "BidirectionalLSTM Validation Accuracy: 0.3400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 8: Visualize the Performance of All Models**\n"
      ],
      "metadata": {
        "id": "-F7GcwIoZb3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the model performance\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(model_performance.keys(), model_performance.values())\n",
        "plt.xlabel(\"Model Type\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.title(\"Validation Accuracy of Different RNN Models\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "XXLphlv5Ze5B",
        "outputId": "d333c442-fc37-4054-bb58-d70c33fdcb37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Summary of Activity\n",
        "\n",
        "In this activity, I aimed to build and evaluate various RNN-based models for sentiment analysis on the SST-5 dataset, which contains customer reviews labeled with sentiment classes ranging from \"very negative\" to \"very positive.\" The objective was to assess the impact of different RNN architectures on text classification performance and understand how they handle the nuances of sentiment analysis.\n",
        "\n",
        "#### Steps Taken:\n",
        "\n",
        "1. **Dataset Preparation**:\n",
        "   - I downloaded the SST-5 dataset from Hugging Face and converted it into DataFrames for easier manipulation.\n",
        "   - I split the training data into an 80:20 ratio, creating separate training and validation sets to monitor the models' generalization.\n",
        "\n",
        "2. **Text Preprocessing**:\n",
        "   - I tokenized the text data using a tokenizer from the Hugging Face library, with a maximum sequence length of 200 and a vocabulary size of 30,000. Any words outside the vocabulary were replaced with an `[OOV]` token to manage out-of-vocabulary words.\n",
        "   - Each sequence was padded to a fixed length of 200 tokens to ensure uniform input size across the models, which is essential for batch processing in deep learning models.\n",
        "\n",
        "3. **Class Imbalance Handling**:\n",
        "   - Given the class imbalance in the dataset, I computed class weights and applied them during training. This adjustment aimed to penalize the model for misclassifying underrepresented classes, encouraging more balanced predictions.\n",
        "\n",
        "4. **Model Training**:\n",
        "   - I trained four different RNN-based models for comparison:\n",
        "      - **Vanilla RNN**: A simple recurrent neural network with a single RNN layer and no directional flexibility.\n",
        "      - **LSTM**: A long short-term memory network, designed to handle longer dependencies and reduce issues like vanishing gradients.\n",
        "      - **GRU**: A gated recurrent unit network, which is a simplified version of LSTM with fewer parameters and potentially faster convergence.\n",
        "      - **Bidirectional LSTM**: An LSTM that processes sequences in both forward and backward directions, capturing context from both past and future tokens.\n",
        "   - Each model was trained for 5 epochs, and dropout layers were applied after the embedding and dense layers to reduce overfitting.\n",
        "\n",
        "5. **Evaluation**:\n",
        "   - After training, I evaluated each model on the validation set and recorded their accuracies. The results were then visualized in a bar chart, providing a comparative view of each model's performance.\n",
        "\n",
        "### Observations on Model Performance\n",
        "\n",
        "- **Vanilla RNN**:\n",
        "  - **Validation Accuracy**: 17.79%\n",
        "  - **Performance Analysis**: The Vanilla RNN struggled with this task, achieving a low validation accuracy. This result suggests that a simple RNN lacks the capacity to capture the complex dependencies required for sentiment analysis, especially in a multiclass setting with nuanced sentiment labels. It is susceptible to vanishing gradients, which hinders its ability to retain information over long sequences.\n",
        "\n",
        "- **LSTM**:\n",
        "  - **Validation Accuracy**: 27.03%\n",
        "  - **Performance Analysis**: The LSTM outperformed the Vanilla RNN, achieving a higher accuracy of 27.03%. LSTM networks are better suited for sequential tasks because they are explicitly designed to manage long-term dependencies through their gated structure. This architecture allows LSTMs to retain information for extended sequences, which is crucial in sentiment analysis, where sentiment cues might span multiple words or even sentences.\n",
        "\n",
        "- **GRU**:\n",
        "  - **Validation Accuracy**: 17.79%\n",
        "  - **Performance Analysis**: The GRU model performed similarly to the Vanilla RNN, with a validation accuracy of 17.79%. Although GRUs are generally more efficient than LSTMs and have fewer parameters, in this case, they did not show an improvement. This outcome could be due to insufficient training epochs or an indication that GRUs are less effective at capturing the complex sentiment relationships in this dataset.\n",
        "\n",
        "- **Bidirectional LSTM**:\n",
        "  - **Validation Accuracy**: 34.00%\n",
        "  - **Performance Analysis**: The Bidirectional LSTM achieved the highest validation accuracy at 34.00%, outperforming all other models. This improvement is likely due to the bidirectional nature of the model, which allows it to learn from both past and future contexts in the sequence. In sentiment analysis, where both preceding and succeeding words can influence the sentiment of a phrase, bidirectional models are particularly advantageous. However, the model also showed signs of overfitting, as indicated by the rise in validation loss despite improved accuracy.\n",
        "\n",
        "### Visualisation of Model Performance\n",
        "\n",
        "The bar chart shows the validation accuracies for each model, highlighting the comparative performance. The Bidirectional LSTM model significantly outperforms the other architectures, followed by the LSTM, while Vanilla RNN and GRU models lag behind.\n",
        "\n",
        "\n",
        "### Reflections and Suggested Improvements\n",
        "\n",
        "- **Hyperparameter Tuning**: The models were trained for only five epochs due to time constraints, and additional training or tuning could yield better results, particularly for GRU and LSTM models.\n",
        "- **Pretrained Embeddings**: Integrating pretrained embeddings, such as GloVe or Word2Vec, could improve the models' understanding of semantic relationships and boost accuracy, especially for the simpler architectures like Vanilla RNN and GRU.\n",
        "- **Increasing Model Complexity**: Adding more layers or units to the LSTM and Bidirectional LSTM models could help improve their capacity to capture more complex patterns in the data.\n",
        "- **Alternative Architectures**: Exploring Transformer-based models, such as BERT, could provide a more modern approach to sentiment classification and potentially deliver significantly better results due to their self-attention mechanism.\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "This activity demonstrated the strengths and weaknesses of various RNN-based models in sentiment analysis. Overall, the Bidirectional LSTM model provided the best results, leveraging bidirectional context to capture sentiment more accurately. However, achieving higher accuracy for this task may require more advanced architectures and further tuning. This exercise highlights the importance of model selection and preprocessing in achieving optimal performance in NLP tasks."
      ],
      "metadata": {
        "id": "3tL4ZfZ_LHMc"
      }
    }
  ]
}