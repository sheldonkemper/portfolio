{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LIrag9UBW4Gx"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sheldonkemper/portfolio/blob/main/CAM_DS_C201_Activity_3_2_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Activity 3.2.3 Experimenting with hyperparameter tuning\n",
        "\n",
        "## Scenario\n",
        "Hopkins et al. (1999) created the Spambase data set donated to the UCI Machine Learning Repository. The data set contains 4,601 emails marked as spam or non-spam by a postmaster or individuals. Fifty-seven features aid in classifying emails as spam (e.g. word frequencies and email characteristics). The Spambase data set is used for developing and benchmarking spam detection models, providing a base for analysing the effectiveness of various machine learning techniques in distinguishing between spam and legitimate emails.\n",
        "\n",
        "As a data professional, you were tasked by your company to develop a neural network with TensorFlow that can classify emails as spam or non-spam. You were tasked to develop a model based on the Spambase data set.\n",
        "\n",
        "\n",
        "\n",
        "## Objective\n",
        "In this portfolio activity, you’ll continue to work with the model you created in Activity 3.1.5 by applying model tuning and grid search to classify emails as spam or non-spam.\n",
        "\n",
        "You will complete the activity in your Notebook, where you’ll:\n",
        "- add an extra four layers to the model you created previously\n",
        "- create a new model pipeline\n",
        "- employ different batch sizes and epochs to evaluate the impact on the accuracy\n",
        "- present your insights based on the performance of the model.\n",
        "\n",
        "\n",
        "## Assessment criteria\n",
        "By completing this activity, you will be able to provide evidence that you can critically select appropriate strategies to demonstrate expertise in model tuning techniques.\n",
        "\n",
        "\n",
        "## Activity guidance\n",
        "1. Continue to work on the model you created in **Activity 3.1.5**.\n",
        "2. Add 4 hidden layers with the ReLU activation and 16 neurons for the fourth layer.\n",
        "3. Compile the model with `binary_crossentropy` as loss, Adam optimiser, and print the accuracy of the model.\n",
        "4. Train and evaluate the model again.\n",
        "5. Jot down whether the final evaluation changed? Was there any improvement in the model? If not, train and evaluate again. Does the final evaluation change? Does it improve?\n",
        "6. Create a vector of different `batch_sizes=np.array([16, 32, 64])` and `loop` through it, retraining the model each time, and print the performances. Use the same model and number of epochs.\n",
        "7. Create a vector of different `epochs=np.array([10, 20, 30])` and `loop` through it, retraining the model each time and using the batch size. Jot down which model gave you the highest accuracy."
      ],
      "metadata": {
        "id": "LIrag9UBW4Gx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Start your activity here. Select the pen from the toolbar to add your entry."
      ],
      "metadata": {
        "id": "N-dwQn8pfPDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start your activity here:\n",
        "\n",
        "# URL to import data set from GitHub.\n",
        "url = 'https://raw.githubusercontent.com/fourthrevlxd/cam_dsb/main/spamdata.csv'"
      ],
      "metadata": {
        "id": "b-rDvxDllBhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(url, header = None)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "chK3ffTypsdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:, -1]"
      ],
      "metadata": {
        "id": "cqYWpHKPlBax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into train and test sets (80% train, 20% test)\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X ,y, test_size=0.2, random_state = 42)\n",
        "# Further split the training set into train and validation (90% train, 10% validation)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size=0.1, random_state = 42)"
      ],
      "metadata": {
        "id": "sMgjjpiylBUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "# Fit the scaler on the training data and transform it\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "sRqAQavCp4aR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model =  tf.keras.Sequential()\n",
        "number_neurons_1 = 64\n",
        "number_neurons_2 = 32\n",
        "\n",
        "#hiden layer 1.\n",
        "model.add(tf.keras.layers.Dense(number_neurons_1,activation = 'relu', input_shape = (X_train.shape[1],)))\n",
        "#hidden layer 2.\n",
        "model.add(tf.keras.layers.Dense(number_neurons_2,activation = 'relu'))\n",
        "#output layer\n",
        "model.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))"
      ],
      "metadata": {
        "id": "46JGtFu1p8By"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model using TensorFlow's alias\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "yxae237Qp_Vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_valid,y_valid))"
      ],
      "metadata": {
        "id": "TH7ImuLYqCfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "# Print the loss and accuracy\n",
        "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')"
      ],
      "metadata": {
        "id": "pU6XQoDVqFql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7Sn4MGNHlSu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3umqhsD3lSpV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reflect\n",
        "\n",
        "Write a brief paragraph highlighting your process and the rationale to showcase critical thinking and problem-solving.\n",
        "\n",
        "> Select the pen from the toolbar to add your entry."
      ],
      "metadata": {
        "id": "qjSjrsKPXtOr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "Hopkins, M., Reeber, E., Forman, G., Suermondt, J., 1999. Spambase. [online]. Available at: https://archive.ics.uci.edu/dataset/94. [Accessed 5 March 2024]."
      ],
      "metadata": {
        "id": "4PPpUhWdek8D"
      }
    }
  ]
}